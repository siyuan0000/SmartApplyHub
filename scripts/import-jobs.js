const fs = require('fs');
const path = require('path');
const csv = require('csv-parser');
const { createClient } = require('@supabase/supabase-js');

// Try to load dotenv if available
try {
  require('dotenv').config({ path: '.env.local' });
} catch (error) {
  console.log('dotenv not found, using environment variables directly');
}

// Check for required environment variables
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

console.log('Environment check:');
console.log('NEXT_PUBLIC_SUPABASE_URL:', supabaseUrl ? 'Set' : 'Missing');
console.log('SUPABASE_SERVICE_ROLE_KEY:', supabaseServiceKey ? 'Set' : 'Missing');

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('\nâŒ Missing required environment variables!');
  console.error('Please set the following in your .env file:');
  console.error('- NEXT_PUBLIC_SUPABASE_URL');
  console.error('- SUPABASE_SERVICE_ROLE_KEY');
  process.exit(1);
}

// Initialize Supabase client
const supabase = createClient(supabaseUrl, supabaseServiceKey);

// CSV file path - check multiple possible locations
const possibleCsvPaths = [
  path.join(__dirname, '..', 'jobs.csv'),
  path.join(process.cwd(), 'jobs.csv'),
  './jobs.csv'
];

function findCsvFile() {
  for (const csvPath of possibleCsvPaths) {
    if (fs.existsSync(csvPath)) {
      console.log(`âœ“ Found CSV file at: ${csvPath}`);
      return csvPath;
    }
  }
  console.error('âŒ Could not find jobs.csv file in any of these locations:');
  possibleCsvPaths.forEach(p => console.error(`   - ${p}`));
  process.exit(1);
}

// CSV column mappings - exact column names from the CSV
const CSV_COLUMNS = {
  SUBMISSION_TIME: 'æäº¤æ—¶é—´ï¼ˆè‡ªåŠ¨ï¼‰',
  ROLE_TYPE: 'æ‚¨æ˜¯ï¼ˆå¿…å¡«ï¼‰',
  NAME: 'å§“åï¼ˆå¿…å¡«ï¼‰',
  SCHOOL: 'å­¦æ ¡ï¼ˆå¿…å¡«ï¼‰',
  COMPANY: 'æ‚¨æ‰€åœ¨å…¬å¸ï¼ˆå¿…å¡«ï¼‰',
  DEPARTMENT: 'æ‚¨æ‰€åœ¨éƒ¨é—¨ï¼ˆå¿…å¡«ï¼‰',
  JOB_LEVEL: 'æ‚¨çš„èŒçº§ï¼ˆå¿…å¡«ï¼‰',
  JOB_REQUIREMENTS: 'æ‹›è˜éœ€æ±‚ï¼ˆå¿…å¡«ï¼‰',
  WECHAT_SUPPORT: 'æŠ•é€’é‚®ç®±ä¹‹å¤–ï¼Œæ˜¯å¦æ”¯æŒå€™é€‰äººæ·»åŠ æ‚¨å¾®ä¿¡ï¼ˆå¿…å¡«ï¼‰',
  JOB_DESCRIPTION: 'æ‹›è˜ä¿¡æ¯å¡«å†™ï¼ˆå¿…å¡«ï¼‰',
  REMOTE_WORK: 'è¯¥å²—ä½èƒ½å¦è¿œç¨‹å·¥ä½œï¼ˆå¿…å¡«ï¼‰',
  WORK_DAYS_PER_WEEK: 'è¯¥å²—ä½éœ€è¦æ¯å‘¨å·¥ä½œå‡ å¤©ï¼ˆå¿…å¡«ï¼‰',
  SALARY: 'è¯¥å²—ä½çš„è–ªèµ„å¾…é‡ï¼ˆå¿…å¡«ï¼‰',
  SPECIAL_PREFERENCES: 'å¯¹å€™é€‰äººæœ‰ä»€ä¹ˆç‰¹æ®Šåå¥½ï¼ˆå¿…å¡«ï¼‰',
  LOCATION: 'è¯¥å²—ä½æ‰€åœ¨åŸŽå¸‚ï¼ˆå¿…å¡«ï¼‰',
  INDUSTRY: 'æ‹›è˜è¡Œä¸šï¼ˆå¿…å¡«ï¼‰',
  SUBMITTER: 'æäº¤è€…ï¼ˆè‡ªåŠ¨ï¼‰'
};

function extractJobTitle(description) {
  // Try to extract job title from the beginning of the description
  if (!description) return 'æ‹›è˜èŒä½';
  
  const lines = description.split('\n');
  const firstLine = lines[0].trim();
  
  // Common patterns for job titles
  if (firstLine.includes('æ‹›è˜')) {
    return firstLine;
  }
  
  // Look for position keywords
  const positionKeywords = ['å®žä¹ ç”Ÿ', 'å·¥ç¨‹å¸ˆ', 'ç»ç†', 'æ€»ç›‘', 'ä¸“å‘˜', 'ä¸»ç®¡', 'åŠ©ç†', 'åˆ†æžå¸ˆ'];
  for (const keyword of positionKeywords) {
    if (firstLine.includes(keyword)) {
      return firstLine.length > 50 ? firstLine.substring(0, 50) + '...' : firstLine;
    }
  }
  
  // Default: use first 30 characters
  return firstLine.length > 30 ? firstLine.substring(0, 30) + '...' : firstLine;
}

function parseServiceTypes(requirements) {
  if (!requirements) return [];
  
  const services = [];
  if (requirements.includes('å…¬ä¼—å·å¤´æ¡å‘å¸ƒ')) services.push('å…¬ä¼—å·å¤´æ¡å‘å¸ƒ');
  if (requirements.includes('å…¬ä¼—å·ä»»æ„ç‰ˆé¢å‘å¸ƒ')) services.push('å…¬ä¼—å·ä»»æ„ç‰ˆé¢å‘å¸ƒ');
  if (requirements.includes('ç¤¾ç¾¤è½¬å‘æ”¯æŒ')) services.push('ç¤¾ç¾¤è½¬å‘æ”¯æŒ');
  if (requirements.includes('ç²¾å‡†ç®€åŽ†æŽ¨è')) services.push('ç²¾å‡†ç®€åŽ†æŽ¨è');
  
  return services;
}

function parseDateFromChinese(dateStr) {
  if (!dateStr) return null;
  
  try {
    // Convert Chinese date format like "2025å¹´5æœˆ12æ—¥ 15:39" to standard format
    const match = dateStr.match(/(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥\s*(\d{1,2}):(\d{2})/);
    if (match) {
      const [, year, month, day, hour, minute] = match;
      const date = new Date(parseInt(year), parseInt(month) - 1, parseInt(day), parseInt(hour), parseInt(minute));
      return date.toISOString();
    }
    
    // Fallback: try direct parsing
    return new Date(dateStr).toISOString();
  } catch (error) {
    console.warn('Could not parse date:', dateStr);
    return null;
  }
}

async function validateDatabaseSchema() {
  console.log('ðŸ” Validating database schema...');
  
  try {
    // Check if required columns exist
    const { data, error } = await supabase
      .from('job_postings')
      .select('id, title, company_name, location, description, department, industry, remote_work_type, contact_method')
      .limit(1);
    
    if (error) {
      if (error.message.includes('column') && error.message.includes('does not exist')) {
        console.error('âŒ Database migration not applied! Missing required columns.');
        console.error('Please run the migration SQL in your Supabase dashboard first.');
        console.error('See apply-migration.md for instructions.');
        process.exit(1);
      }
      throw error;
    }
    
    console.log('âœ“ Database schema validation passed');
    return true;
  } catch (error) {
    console.error('âŒ Database connection or schema error:', error.message);
    process.exit(1);
  }
}

function transformRowToJob(row) {
  const jobDescription = row[CSV_COLUMNS.JOB_DESCRIPTION] || '';
  const jobTitle = extractJobTitle(jobDescription);
  
  return {
    title: jobTitle,
    company_name: row[CSV_COLUMNS.COMPANY] || '',
    location: row[CSV_COLUMNS.LOCATION] || '',
    description: jobDescription,
    requirements: row[CSV_COLUMNS.JOB_REQUIREMENTS] || '',
    salary_range: row[CSV_COLUMNS.SALARY] || '',
    job_type: 'full-time', // Default, could be enhanced based on description
    department: row[CSV_COLUMNS.DEPARTMENT] || '',
    job_level: row[CSV_COLUMNS.JOB_LEVEL] || '',
    industry: row[CSV_COLUMNS.INDUSTRY] || '',
    remote_work_type: row[CSV_COLUMNS.REMOTE_WORK] || '',
    work_days_per_week: row[CSV_COLUMNS.WORK_DAYS_PER_WEEK] || '',
    contact_method: row[CSV_COLUMNS.WECHAT_SUPPORT] || '',
    special_preferences: row[CSV_COLUMNS.SPECIAL_PREFERENCES] || '',
    submitter_name: row[CSV_COLUMNS.SUBMITTER] || '',
    recruiter_type: row[CSV_COLUMNS.ROLE_TYPE] || '',
    service_types: parseServiceTypes(row[CSV_COLUMNS.JOB_REQUIREMENTS]),
    submission_date: parseDateFromChinese(row[CSV_COLUMNS.SUBMISSION_TIME]) || new Date().toISOString()
  };
}

async function importJobsFromCSV() {
  // Validate database schema first
  await validateDatabaseSchema();
  
  // Find the CSV file
  const csvPath = findCsvFile();
  
  const jobs = [];
  let columnNames = [];
  let isFirstRow = true;

  console.log('Starting CSV import...');
  console.log('Expected column mappings:');
  console.log(JSON.stringify(CSV_COLUMNS, null, 2));

  return new Promise((resolve, reject) => {
    fs.createReadStream(csvPath)
      .pipe(csv())
      .on('headers', (headers) => {
        columnNames = headers;
        console.log('\n=== ACTUAL CSV COLUMN NAMES ===');
        headers.forEach((header, index) => {
          console.log(`${index + 1}: "${header}"`);
        });
        console.log('================================\n');
        
        // Verify all expected columns exist
        const missingColumns = [];
        Object.values(CSV_COLUMNS).forEach(expectedCol => {
          if (!headers.includes(expectedCol)) {
            missingColumns.push(expectedCol);
          }
        });
        
        if (missingColumns.length > 0) {
          console.warn('Missing columns:', missingColumns);
        }
      })
      .on('data', (row) => {
        if (isFirstRow) {
          console.log('\n=== SAMPLE ROW DATA ===');
          console.log('First row data:');
          Object.keys(row).forEach(key => {
            console.log(`"${key}": "${row[key]}"`);
          });
          console.log('=====================\n');
          isFirstRow = false;
        }

        try {
          const job = transformRowToJob(row);
          
          // Only add if we have essential data
          if (job.company_name && job.description) {
            jobs.push(job);
            if (jobs.length <= 5) {
              console.log(`âœ“ Successfully processed job ${jobs.length}:`, {
                title: job.title,
                company: job.company_name,
                location: job.location
              });
            }
          } else {
            console.log('Skipping row with missing essential data:', {
              company: job.company_name,
              hasDescription: !!job.description
            });
          }
        } catch (error) {
          console.error('Error processing row:', error);
          console.log('Problematic row data:', {
            company: row[CSV_COLUMNS.COMPANY],
            description: row[CSV_COLUMNS.JOB_DESCRIPTION]
          });
        }
      })
      .on('end', async () => {
        console.log(`\nParsed ${jobs.length} jobs from CSV`);
        
        if (jobs.length > 0) {
          console.log('\n=== SAMPLE TRANSFORMED JOB ===');
          console.log(JSON.stringify(jobs[0], null, 2));
          console.log('===============================\n');
          
          try {
            // Insert jobs in smaller batches for better reliability
            const batchSize = 50;
            let inserted = 0;
            let failed = 0;
            
            console.log(`\nðŸ“¤ Starting batch insert process...`);
            console.log(`Total jobs to insert: ${jobs.length}`);
            console.log(`Batch size: ${batchSize}`);
            
            for (let i = 0; i < jobs.length; i += batchSize) {
              const batch = jobs.slice(i, i + batchSize);
              const batchNum = Math.floor(i/batchSize) + 1;
              const totalBatches = Math.ceil(jobs.length/batchSize);
              
              console.log(`\nðŸ“‹ Processing batch ${batchNum}/${totalBatches} (${batch.length} jobs)...`);
              
              try {
                const { data, error } = await supabase
                  .from('job_postings')
                  .insert(batch);
                
                if (error) {
                  console.error(`âŒ Batch ${batchNum} failed:`, error);
                  failed += batch.length;
                  
                  // Try inserting individual records in this batch
                  console.log(`ðŸ”„ Attempting individual inserts for batch ${batchNum}...`);
                  for (const job of batch) {
                    try {
                      const { error: singleError } = await supabase
                        .from('job_postings')
                        .insert([job]);
                      
                      if (singleError) {
                        console.error(`âŒ Failed to insert job: ${job.title} from ${job.company_name}`);
                        console.error('Error:', singleError.message);
                      } else {
                        inserted++;
                      }
                    } catch (singleJobError) {
                      console.error(`âŒ Exception inserting single job:`, singleJobError.message);
                    }
                  }
                } else {
                  inserted += batch.length;
                  console.log(`âœ… Batch ${batchNum} completed successfully`);
                }
              } catch (batchError) {
                console.error(`âŒ Exception in batch ${batchNum}:`, batchError.message);
                failed += batch.length;
              }
              
              // Progress update
              const progress = ((batchNum / totalBatches) * 100).toFixed(1);
              console.log(`ðŸ“Š Progress: ${progress}% (${inserted} inserted, ${failed} failed)`);
              
              // Small delay to avoid rate limiting
              if (batchNum < totalBatches) {
                await new Promise(resolve => setTimeout(resolve, 100));
              }
            }
            
            console.log(`\nðŸŽ‰ Import completed!`);
            console.log(`âœ… Successfully imported: ${inserted} jobs`);
            console.log(`âŒ Failed to import: ${failed} jobs`);
            console.log(`ðŸ“ˆ Success rate: ${((inserted / jobs.length) * 100).toFixed(1)}%`);
            
            resolve(inserted);
          } catch (error) {
            console.error('Error inserting jobs:', error);
            reject(error);
          }
        } else {
          console.log('No valid jobs to import');
          resolve(0);
        }
      })
      .on('error', (error) => {
        console.error('CSV parsing error:', error);
        reject(error);
      });
  });
}

// Run the import
if (require.main === module) {
  importJobsFromCSV()
    .then((count) => {
      console.log(`Import completed: ${count} jobs imported`);
      process.exit(0);
    })
    .catch((error) => {
      console.error('Import failed:', error);
      process.exit(1);
    });
}

module.exports = { importJobsFromCSV };